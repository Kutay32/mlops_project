# -*- coding: utf-8 -*-
"""dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q2mF1FDFi3WiFjepPZYl1ayZvHgeizBm

This dataset belongs to the telecommunications (telecom) industry. It has been cleaned and prepared to support churn prediction modeling based on customer subscription, billing, and service usage behavior.
"""

import pandas as pd

url = "https://raw.githubusercontent.com/Nas-virat/Telco-Customer-Churn/main/Telco-Customer-Churn.csv"
df = pd.read_csv(url)
df.head()

print("Dataset shape:", df.shape)

df = df.drop_duplicates()

print("\nMissing values before cleaning:\n", df.isnull().sum())

df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

num_cols = df.select_dtypes(include=["float64", "int64"]).columns
for col in num_cols:
    df[col] = df[col].fillna(df[col].median())

cat_cols = df.select_dtypes(include=["object"]).columns
for col in cat_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})

if "customerID" in df.columns:
    df = df.drop(columns=["customerID"])

print("\nMissing values after cleaning:\n", df.isnull().sum())

df = pd.get_dummies(df, drop_first=True)

print("\nFinal dataset shape (after encoding):", df.shape)
df.head()

from sklearn.model_selection import train_test_split

def load_data():
    url = "https://raw.githubusercontent.com/Nas-virat/Telco-Customer-Churn/main/Telco-Customer-Churn.csv"
    df = pd.read_csv(url)
    print(f"Loaded dataset from telecom industry. Shape: {df.shape}")
    return df

def preprocess_data(df):
    df = df.drop_duplicates()
    df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

    # Fill missing values
    num_cols = df.select_dtypes(include=["float64", "int64"]).columns
    for col in num_cols:
        df[col] = df[col].fillna(df[col].median())

    cat_cols = df.select_dtypes(include=["object"]).columns
    for col in cat_cols:
        df[col] = df[col].fillna(df[col].mode()[0])

    # Convert target
    df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})

    # Drop ID
    if "customerID" in df.columns:
        df = df.drop(columns=["customerID"])

    # One-Hot Encode
    df = pd.get_dummies(df, drop_first=True)

    print("Preprocessing completed. Final shape:", df.shape)
    return df

def split_data(df):
    X = df.drop(columns=["Churn"])
    y = df["Churn"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    print("Data split with stratification:")
    print("Train size:", X_train.shape, "| Churn rate:", y_train.mean())
    print("Test size:", X_test.shape, "| Churn rate:", y_test.mean())

    return X_train, X_test, y_train, y_test

def save_cleaned_data(df):
    df.to_csv("clean_telco_churn.csv", index=False)
    print("Cleaned churn dataset saved as clean_telco_churn.csv (telecom domain, ML-ready).")

if __name__ == "__main__":
    df = load_data()
    df = preprocess_data(df)
    X_train, X_test, y_train, y_test = split_data(df)
    save_cleaned_data(df)

df.head()